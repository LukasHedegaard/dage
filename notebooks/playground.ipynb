{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from operator import mul\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution() \n",
    "m = tf.compat.v2.math\n",
    "keras = tf.compat.v2.keras\n",
    "K = keras.backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test setup\n",
    "def test_layer(make_layer):\n",
    "    VALUE_SHAPE = (3,)\n",
    "    \n",
    "    in_vals = [\n",
    "        np.array([\n",
    "            np.reshape(np.arange(0,reduce(mul, VALUE_SHAPE), dtype=np.dtype('float32')), VALUE_SHAPE)-10,\n",
    "            np.reshape(np.arange(0,reduce(mul, VALUE_SHAPE), dtype=np.dtype('float32')), VALUE_SHAPE),\n",
    "        ]),\n",
    "        np.array([\n",
    "            np.ones(VALUE_SHAPE, dtype=np.dtype('float32')),\n",
    "            np.zeros(VALUE_SHAPE, dtype=np.dtype('float32'))\n",
    "        ])\n",
    "    ]\n",
    "    \n",
    "    out_val = make_layer()(in_vals)\n",
    "    return out_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17.378147],\n",
       "       [ 2.236068]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CCSA-keras implementation\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    eps = 1e-08\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), eps))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def make_euc_dist():\n",
    "    return keras.layers.Lambda(\n",
    "        euclidean_distance, \n",
    "        output_shape=eucl_dist_output_shape, name='CSA'\n",
    "    )\n",
    "\n",
    "test_layer(make_euc_dist).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17.378147,  2.236068], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# custom distance layer implementation\n",
    "M = tf.compat.v2.math\n",
    "class Distance(keras.layers.Layer):\n",
    "    '''\n",
    "    Frobenius Norm of distance between inputs.\n",
    "    Assumes the input two be array-like with two elements\n",
    "    Implementation only supports 1D data\n",
    "    '''\n",
    "    def __init__(self, name=None):\n",
    "        super(Distance, self).__init__(name=name)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        a = inputs[0]\n",
    "        b = inputs[1]\n",
    "        return M.square(M.sqrt(M.reduce_sum(M.square(a-b),axis=1)))\n",
    "\n",
    "M.sqrt(test_layer(Distance).numpy()).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld = [\n",
    "    {'a':1, 'b':10},\n",
    "    {'a':2, 'b':20},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 3, 'b': 30}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(lambda dn, do: {k:dn[k]+do[k] for k in dn},ld, {k:0 for k in ld[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = [\n",
    "    [1,10],\n",
    "    [2,20]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 30]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(\n",
    "    lambda n, o: [n[i]+o[i] for i in range(len(ll))],\n",
    "    ll, \n",
    "    [0 for _ in ll[0]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2 #batch size\n",
    "es = 3 # embed size\n",
    "xs = tf.constant([[1,2,3],[4,5,6]], dtype=tf.float32)\n",
    "xt = tf.constant([[3,2,1],[4,4,4]], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_rpt = tf.broadcast_to(tf.expand_dims(xs, axis=0),shape=(bs,bs,es),name=None)\n",
    "xt_rpt = tf.broadcast_to(tf.expand_dims(xt, axis=1),shape=(bs,bs,es),name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=420, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[ 8., 35.],\n",
       "       [14.,  5.]], dtype=float32)>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists = tf.reduce_sum(tf.square(xs_rpt-xt_rpt), axis=2)\n",
    "dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = tf.constant([0,1])\n",
    "yt = tf.constant([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_rpt = tf.broadcast_to(tf.expand_dims(ys, axis=1), shape=(bs, bs))\n",
    "yt_rpt = tf.broadcast_to(tf.expand_dims(yt, axis=0), shape=(bs, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=468, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[0., 0.],\n",
       "        [1., 0.]], dtype=float32)>,\n",
       " <tf.Tensor: id=470, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[1., 1.],\n",
       "        [0., 1.]], dtype=float32)>)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_same = tf.cast(tf.equal(ys_rpt,yt_rpt), tf.float32)\n",
    "y_diff = tf.cast(tf.not_equal(ys_rpt,yt_rpt), tf.float32)\n",
    "y_same, y_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=473, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[ 0.,  0.],\n",
       "        [14.,  0.]], dtype=float32)>,\n",
       " <tf.Tensor: id=474, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[ 8., 35.],\n",
       "        [ 0.,  5.]], dtype=float32)>)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intra_cls_dists = tf.multiply(sum_square, y_same)\n",
    "inter_cls_dists = tf.multiply(sum_square, y_diff)\n",
    "intra_cls_dists, inter_cls_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=480, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[35., 35.],\n",
       "       [14., 14.]], dtype=float32)>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_dists = tf.reduce_max(dists, axis=1, keepdims=True)\n",
    "max_dists = tf.broadcast_to(max_dists, shape=(bs, bs))\n",
    "max_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=468, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[0., 0.],\n",
       "        [1., 0.]], dtype=float32)>,\n",
       " <tf.Tensor: id=480, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[35., 35.],\n",
       "        [14., 14.]], dtype=float32)>,\n",
       " <tf.Tensor: id=474, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[ 8., 35.],\n",
       "        [ 0.,  5.]], dtype=float32)>)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_same, max_dists, inter_cls_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=491, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[ 8., 35.],\n",
       "       [14.,  5.]], dtype=float32)>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revised_inter_cls_dists = tf.where(tf.cast(y_same, dtype=tf.bool), max_dists, inter_cls_dists)\n",
    "revised_inter_cls_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=494, shape=(2,), dtype=float32, numpy=array([ 0., 14.], dtype=float32)>,\n",
       " <tf.Tensor: id=496, shape=(2,), dtype=float32, numpy=array([8., 5.], dtype=float32)>)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_intra_cls_dist = tf.reduce_max(intra_cls_dists, axis=1)\n",
    "min_inter_cls_dist = tf.reduce_min(revised_inter_cls_dists, axis=1)\n",
    "max_intra_cls_dist, min_inter_cls_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=518, shape=(2,), dtype=float32, numpy=array([0., 9.], dtype=float32)>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "margin=0\n",
    "tf.nn.relu(max_intra_cls_dist - min_inter_cls_dist + margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ho(a):\n",
    "    def fn(b):\n",
    "        return a+b\n",
    "    return fn\n",
    "\n",
    "ho(2)(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys=tf.constant([1,2,1])\n",
    "yt=tf.constant([1,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=528, shape=(3,), dtype=float32, numpy=array([1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast(tf.equal(ys,yt), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=520, shape=(3,), dtype=int32, numpy=array([1, 2, 1], dtype=int32)>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dimension(3)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2), Dimension(3)])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.compat.v2.TensorShape([2,ys.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=638, shape=(2, 2, 3), dtype=int32, numpy=\n",
       "array([[[1, 0, 0],\n",
       "        [0, 1, 0]],\n",
       "\n",
       "       [[1, 0, 0],\n",
       "        [0, 0, 1]]], dtype=int32)>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = tf.constant([[[1,0,0],[0,1,0]], [[1,0,0],[0,0,1]]])\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=683, shape=(2, 3), dtype=int32, numpy=\n",
       " array([[1, 0, 0],\n",
       "        [0, 1, 0]], dtype=int32)>,\n",
       " <tf.Tensor: id=687, shape=(2, 3), dtype=int32, numpy=\n",
       " array([[1, 0, 0],\n",
       "        [0, 0, 1]], dtype=int32)>)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys, yt = y_true\n",
    "ys, yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=733, shape=(2, 1), dtype=float32, numpy=\n",
       "array([[1.],\n",
       "       [0.]], dtype=float32)>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast(tf.reduce_all(tf.equal(ys,yt),axis=1, keepdims=True), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=673, shape=(2, 3), dtype=int32, numpy=\n",
       "array([[ 0,  0,  0],\n",
       "       [ 0,  1, -1]], dtype=int32)>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys-yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=738, shape=(2, 3), dtype=int32, numpy=\n",
       "array([[1, 0, 0],\n",
       "       [0, 1, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.square(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = tf.constant([[1,2,3],[4,5,6]], dtype=tf.float32)\n",
    "xt = tf.constant([[3,2,1],[4,4,4]], dtype=tf.float32)\n",
    "ys = tf.constant([0,1])\n",
    "yt = tf.constant([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.constant([[[True, False, False], [True, False, False]],\n",
    "                      [[False, False, True], [False, False, True]]])\n",
    "\n",
    "y_pred = tf.constant([[[1,2,3],[4,5,6]],\n",
    "                      [[3,2,1],[4,4,4]]], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=1665, shape=(2,), dtype=int64, numpy=array([0, 2])>,\n",
       " <tf.Tensor: id=1672, shape=(2,), dtype=int64, numpy=array([0, 2])>,\n",
       " <tf.Tensor: id=1676, shape=(2, 3), dtype=float32, numpy=\n",
       " array([[1., 2., 3.],\n",
       "        [3., 2., 1.]], dtype=float32)>,\n",
       " <tf.Tensor: id=1680, shape=(2, 3), dtype=float32, numpy=\n",
       " array([[4., 5., 6.],\n",
       "        [4., 4., 4.]], dtype=float32)>,\n",
       " <tf.Tensor: id=1684, shape=(3, 4), dtype=float32, numpy=\n",
       " array([[1., 3., 4., 4.],\n",
       "        [2., 2., 5., 4.],\n",
       "        [3., 1., 6., 4.]], dtype=float32)>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = tf.argmax(tf.cast(y_true[:,0], dtype=tf.int32), axis=1)\n",
    "yt = tf.argmax(tf.cast(y_true[:,1], dtype=tf.int32), axis=1)\n",
    "xs = y_pred[:,0]\n",
    "xt = y_pred[:,1]\n",
    "θϕ = tf.transpose(tf.concat([xs,xt], axis=0))\n",
    "ys, yt, xs, xt, θϕ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = ys.shape[0].value\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,\n",
       " <tf.Tensor: id=1731, shape=(4,), dtype=int64, numpy=array([0, 2, 0, 2])>,\n",
       " <tf.Tensor: id=1735, shape=(4, 4), dtype=int64, numpy=\n",
       " array([[0, 0, 0, 0],\n",
       "        [2, 2, 2, 2],\n",
       "        [0, 0, 0, 0],\n",
       "        [2, 2, 2, 2]])>,\n",
       " <tf.Tensor: id=1739, shape=(4, 4), dtype=int64, numpy=\n",
       " array([[0, 2, 0, 2],\n",
       "        [0, 2, 0, 2],\n",
       "        [0, 2, 0, 2],\n",
       "        [0, 2, 0, 2]])>,\n",
       " <tf.Tensor: id=1740, shape=(4, 4), dtype=bool, numpy=\n",
       " array([[ True, False,  True, False],\n",
       "        [False,  True, False,  True],\n",
       "        [ True, False,  True, False],\n",
       "        [False,  True, False,  True]])>,\n",
       " <tf.Tensor: id=1741, shape=(4, 4), dtype=bool, numpy=\n",
       " array([[False,  True, False,  True],\n",
       "        [ True, False,  True, False],\n",
       "        [False,  True, False,  True],\n",
       "        [ True, False,  True, False]])>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make_weights: relate_all\n",
    "N = 2*batch_size \n",
    "y = tf.concat([ys, yt], axis = 0) # TODO: verify axis\n",
    "yTe = tf.broadcast_to(tf.expand_dims(y, axis=1), shape=(N, N))\n",
    "eTy = tf.broadcast_to(tf.expand_dims(y, axis=0), shape=(N, N))\n",
    "\n",
    "W = tf.equal(yTe, eTy)\n",
    "Wp = tf.not_equal(yTe, eTy)\n",
    "N, y, yTe, eTy, W, Wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/da/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py:253: _EagerTensorBase.cpu (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.identity instead.\n",
      "WARNING:tensorflow:From <ipython-input-67-a265d8b2121d>:7: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=1728, shape=(4, 4), dtype=bool, numpy=\n",
       " array([[False, False,  True, False],\n",
       "        [False, False, False,  True],\n",
       "        [ True, False, False, False],\n",
       "        [False,  True, False, False]])>,\n",
       " <tf.Tensor: id=1729, shape=(4, 4), dtype=bool, numpy=\n",
       " array([[False, False, False,  True],\n",
       "        [False, False,  True, False],\n",
       "        [False,  True, False, False],\n",
       "        [ True, False, False, False]])>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make weights: relate source-target\n",
    "N = 2*batch_size \n",
    "tile_size = [batch_size, batch_size]\n",
    "i = tf.concat([ tf.concat([tf.zeros(tile_size, dtype=tf.bool), tf.ones(tile_size, dtype=tf.bool)], axis=0),\n",
    "                tf.concat([tf.ones(tile_size, dtype=tf.bool), tf.zeros(tile_size, dtype=tf.bool)], axis=0) ], axis=1 )\n",
    "zeros = tf.zeros([N,N],dtype=tf.bool)\n",
    "W = tf.where(i, W, zeros)\n",
    "Wp = tf.where(i, Wp, zeros)\n",
    "W, Wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=1080, shape=(2, 2), dtype=bool, numpy=\n",
       " array([[ True, False],\n",
       "        [False,  True]])>,\n",
       " <tf.Tensor: id=1082, shape=(2, 2), dtype=bool, numpy=\n",
       " array([[False, False],\n",
       "        [False, False]])>,\n",
       " <tf.Tensor: id=1093, shape=(4, 4), dtype=bool, numpy=\n",
       " array([[False, False,  True, False],\n",
       "        [False, False, False,  True],\n",
       "        [ True, False, False, False],\n",
       "        [False,  True, False, False]])>,\n",
       " <tf.Tensor: id=1099, shape=(4, 4), dtype=bool, numpy=\n",
       " array([[False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])>)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make weights: relate source-target pair\n",
    "eq = tf.linalg.diag(tf.equal(ys, yt))\n",
    "neq = tf.linalg.diag(tf.not_equal(ys, yt))\n",
    "zeros = tf.zeros([batch_size, batch_size],dtype=tf.bool)\n",
    "W = tf.concat([tf.concat([zeros, eq],axis=0),\n",
    "               tf.concat([eq, zeros],axis=0)], axis=1)\n",
    "Wp = tf.concat([tf.concat([zeros, neq],axis=0),\n",
    "                tf.concat([neq, zeros],axis=0)], axis=1)\n",
    "eq, neq, W, Wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, Wp = tf.cast(W, dtype=tf.float32), tf.cast(Wp, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=1104, shape=(4, 4), dtype=float32, numpy=\n",
       " array([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.]], dtype=float32)>,\n",
       " <tf.Tensor: id=1107, shape=(4, 4), dtype=float32, numpy=\n",
       " array([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]], dtype=float32)>)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D  = tf.linalg.diag(tf.reduce_sum(W,  axis=1)) \n",
    "Dp = tf.linalg.diag(tf.reduce_sum(Wp, axis=1))\n",
    "D, Dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=1108, shape=(4, 4), dtype=float32, numpy=\n",
       " array([[ 1.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0., -1.],\n",
       "        [-1.,  0.,  1.,  0.],\n",
       "        [ 0., -1.,  0.,  1.]], dtype=float32)>,\n",
       " <tf.Tensor: id=1109, shape=(4, 4), dtype=float32, numpy=\n",
       " array([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]], dtype=float32)>)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L  = tf.subtract(D, W)\n",
    "Lp = tf.subtract(Dp, Wp)\n",
    "L, Lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=988, shape=(3, 3), dtype=float32, numpy=\n",
       " array([[10., 11., 12.],\n",
       "        [11., 13., 15.],\n",
       "        [12., 15., 18.]], dtype=float32)>,\n",
       " <tf.Tensor: id=990, shape=(3, 3), dtype=float32, numpy=\n",
       " array([[10.,  9.,  8.],\n",
       "        [ 9., 13., 17.],\n",
       "        [ 8., 17., 26.]], dtype=float32)>)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "θϕLϕθ  = tf.matmul(θϕ, tf.matmul(L,  θϕ, transpose_b=True))\n",
    "θϕLpϕθ = tf.matmul(θϕ, tf.matmul(Lp, θϕ, transpose_b=True))\n",
    "θϕLϕθ, θϕLpϕθ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=997, shape=(), dtype=float32, numpy=0.8367347>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = tf.linalg.trace(θϕLϕθ) / tf.linalg.trace(θϕLpϕθ)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../losses/dage.py:38: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=14, shape=(6, 6), dtype=bool, numpy=\n",
       " array([[ True,  True,  True,  True,  True,  True],\n",
       "        [ True,  True,  True,  True,  True,  True],\n",
       "        [ True,  True,  True,  True,  True,  True],\n",
       "        [ True,  True,  True,  True,  True,  True],\n",
       "        [ True,  True,  True,  True,  True,  True],\n",
       "        [ True,  True,  True,  True,  True,  True]])>,\n",
       " <tf.Tensor: id=46, shape=(6, 6), dtype=float32, numpy=\n",
       " array([[ 0., 27.,  9.,  8., 14., 17.],\n",
       "        [27.,  0., 30., 35.,  5., 26.],\n",
       "        [ 9., 30.,  0.,  1., 11.,  2.],\n",
       "        [ 8., 35.,  1.,  0., 14.,  5.],\n",
       "        [14.,  5., 11., 14.,  0.,  9.],\n",
       "        [17., 26.,  2.,  5.,  9.,  0.]], dtype=float32)>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from losses.dage import dist2indicator, dist2gaussian, relate_all, relate_source_target, make_filter, FilterType \n",
    "\n",
    "xs = tf.constant([[1,2,3],[4,5,6],[3,3,1]], dtype=tf.float32)\n",
    "xt = tf.constant([[3,2,1],[4,4,4],[4,4,1]], dtype=tf.float32)\n",
    "ys = tf.constant([0,0,0])\n",
    "yt = tf.constant([0,0,0])\n",
    "batch_size = 3\n",
    "\n",
    "W, Wp = relate_all(ys,yt,batch_size)\n",
    "# W_Wp = relate_source_target(ys,yt,batch_size)\n",
    "\n",
    "filt = make_filter(\n",
    "    filter_type=FilterType.ALL, #ALL, KNN, KFN, EPSILON,\n",
    "    penalty_filter_type=FilterType.ALL, \n",
    "    filter_param=1, \n",
    "    penalty_filter_param=1\n",
    ")\n",
    "W_filt, Wp_filt = filt((W, Wp), xs, xt)\n",
    "\n",
    "W, W_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=140, shape=(6, 6), dtype=float32, numpy=\n",
       "array([[ 0., 27.,  0.,  0.,  0., 17.],\n",
       "       [ 0.,  0., 30., 35.,  0.,  0.],\n",
       "       [ 0., 30.,  0.,  0., 11.,  0.],\n",
       "       [ 0., 35.,  0.,  0., 14.,  0.],\n",
       "       [14.,  0.,  0., 14.,  0.,  0.],\n",
       "       [17., 26.,  0.,  0.,  0.,  0.]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = make_filter(\n",
    "    filter_type=FilterType.KNN, #ALL, KNN, KFN, EPSILON,\n",
    "    penalty_filter_type=FilterType.KNN, \n",
    "    filter_param=2, \n",
    "    penalty_filter_param=1\n",
    ")\n",
    "W_filt, Wp_filt = filt((W, Wp), xs, xt)\n",
    "\n",
    "W_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=303, shape=(6, 6), dtype=float32, numpy=\n",
       "array([[ 0.,  0.,  9.,  8.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  5., 26.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  2.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  5.],\n",
       "       [ 0.,  5.,  0.,  0.,  0.,  9.],\n",
       "       [ 0.,  0.,  2.,  5.,  0.,  0.]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = make_filter(\n",
    "    filter_type=FilterType.KFN, #ALL, KNN, KFN, EPSILON,\n",
    "    penalty_filter_type=FilterType.KNN, \n",
    "    filter_param=2, \n",
    "    penalty_filter_param=1\n",
    ")\n",
    "W_filt, Wp_filt = filt((W, Wp), xs, xt)\n",
    "\n",
    "W_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=404, shape=(6, 6), dtype=float32, numpy=\n",
       "array([[0., 0., 9., 8., 0., 0.],\n",
       "       [0., 0., 0., 0., 5., 0.],\n",
       "       [9., 0., 0., 1., 0., 2.],\n",
       "       [8., 0., 1., 0., 0., 5.],\n",
       "       [0., 5., 0., 0., 0., 9.],\n",
       "       [0., 0., 2., 5., 9., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = make_filter(\n",
    "    filter_type=FilterType.EPSILON, #ALL, KNN, KFN, EPSILON,\n",
    "    penalty_filter_type=FilterType.KNN, \n",
    "    filter_param=10, \n",
    "    penalty_filter_param=1\n",
    ")\n",
    "W_filt, Wp_filt = filt((W, Wp), xs, xt)\n",
    "\n",
    "W_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=471, shape=(6, 6), dtype=float32, numpy=\n",
       "array([[0., 0., 1., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 1., 0., 1.],\n",
       "       [1., 0., 1., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 1., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist2indicator(W_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=476, shape=(6, 6), dtype=float32, numpy=\n",
       "array([[0.0000000e+00, 0.0000000e+00, 1.2340980e-04, 3.3546262e-04,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        6.7379470e-03, 0.0000000e+00],\n",
       "       [1.2340980e-04, 0.0000000e+00, 0.0000000e+00, 3.6787945e-01,\n",
       "        0.0000000e+00, 1.3533528e-01],\n",
       "       [3.3546262e-04, 0.0000000e+00, 3.6787945e-01, 0.0000000e+00,\n",
       "        0.0000000e+00, 6.7379470e-03],\n",
       "       [0.0000000e+00, 6.7379470e-03, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 1.2340980e-04],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.3533528e-01, 6.7379470e-03,\n",
       "        1.2340980e-04, 0.0000000e+00]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist2gaussian(W_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HEY'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'hey'.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.constant([[1,2,3],[4,5,6],[3,2,1],[4,4,4]], dtype=tf.float32)\n",
    "\n",
    "N = 4\n",
    "D = 3\n",
    "input_shape = (D)\n",
    "embed_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = keras.layers.Input(shape=(D))\n",
    "\n",
    "f = keras.layers.Dense(embed_size, activation=None, kernel_initializer='glorot_uniform', bias_initializer='zeros', name='attention_f')\n",
    "g = keras.layers.Dense(embed_size, activation=None, kernel_initializer='glorot_uniform', bias_initializer='zeros', name='attention_g')\n",
    "T = keras.layers.Lambda(K.transpose)\n",
    "\n",
    "matmul = keras.layers.Lambda(lambda x: tf.tensordot(x[0], x[1], axes=(1)))\n",
    "softmax = keras.layers.Activation('softmax', name='attention_softmax')\n",
    "\n",
    "out = softmax(matmul([(f(i)),T(g(i))]))\n",
    "model=keras.models.Model(inputs=[i], outputs=[out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=12453, shape=(4, 4), dtype=float32, numpy=\n",
       "array([[1.00125641e-01, 7.40036309e-01, 1.46276085e-02, 1.45210475e-01],\n",
       "       [2.00351864e-01, 7.85571873e-01, 1.56418930e-04, 1.39198992e-02],\n",
       "       [9.28939700e-01, 5.39749973e-02, 5.94088621e-03, 1.11443959e-02],\n",
       "       [6.90710783e-01, 2.96626180e-01, 6.45339838e-04, 1.20176254e-02]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -2.9019809 , -13.562158  , -11.311586  , -14.213565  ],\n",
       "       [ -1.4538176 , -17.588102  , -20.058567  , -21.51238   ],\n",
       "       [  4.8328657 ,   8.194226  ,  -0.35105208,   4.481814  ],\n",
       "       [  1.9308851 ,  -5.367931  , -11.662639  ,  -9.731753  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fX = f(X).numpy()\n",
    "gX = g(X).numpy()\n",
    "fX @ gX.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True]])"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fX = f(X).numpy()\n",
    "gX = g(X).numpy()\n",
    "fX.transpose() == T(f(X)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True]])"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matmul = keras.layers.Lambda(lambda x: tf.tensordot(x[0], x[1], axes=(1)))\n",
    "fX @ gX.transpose() == matmul(((f(X)),T(g(X)))).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True]])"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(fX @ gX.transpose()).numpy() == model(X).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=12330, shape=(4, 3), dtype=float32, numpy=\n",
       " array([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [3., 2., 1.],\n",
       "        [4., 4., 4.]], dtype=float32)>,\n",
       " <tf.Tensor: id=12550, shape=(4, 1), dtype=float32, numpy=\n",
       " array([[1.],\n",
       "        [4.],\n",
       "        [3.],\n",
       "        [4.]], dtype=float32)>,\n",
       " <tf.Tensor: id=12554, shape=(4, 1), dtype=float32, numpy=\n",
       " array([[2.],\n",
       "        [5.],\n",
       "        [2.],\n",
       "        [4.]], dtype=float32)>,\n",
       " <tf.Tensor: id=12558, shape=(4, 1), dtype=float32, numpy=\n",
       " array([[3.],\n",
       "        [6.],\n",
       "        [1.],\n",
       "        [4.]], dtype=float32)>)"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X[:,:-2], X[:,-2:-1], X[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=12580, shape=(12, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  2.,  3.],\n",
       "       [ 4.,  5.,  6.],\n",
       "       [ 3.,  2.,  1.],\n",
       "       [ 4.,  4.,  4.],\n",
       "       [10., 20., 30.],\n",
       "       [40., 50., 60.],\n",
       "       [30., 20., 10.],\n",
       "       [40., 40., 40.],\n",
       "       [-1., -2., -3.],\n",
       "       [-4., -5., -6.],\n",
       "       [-3., -2., -1.],\n",
       "       [-4., -4., -4.]], dtype=float32)>"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = keras.layers.Concatenate(axis=0)([X, 10*X, -X])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=12640, shape=(4, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.],\n",
       "       [3., 2., 1.],\n",
       "       [4., 4., 4.]], dtype=float32)>"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:-2*N,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = N//2\n",
    "Ap = y_pred[-N:,:]\n",
    "A  = y_pred[-2*N:-N,:]\n",
    "θϕ = y_pred[:-2*N,:]\n",
    "xs = θϕ[:,:-batch_size]\n",
    "xt = θϕ[:,-batch_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=12644, shape=(4, 3), dtype=float32, numpy=\n",
       " array([[-1., -2., -3.],\n",
       "        [-4., -5., -6.],\n",
       "        [-3., -2., -1.],\n",
       "        [-4., -4., -4.]], dtype=float32)>,\n",
       " <tf.Tensor: id=12648, shape=(4, 3), dtype=float32, numpy=\n",
       " array([[10., 20., 30.],\n",
       "        [40., 50., 60.],\n",
       "        [30., 20., 10.],\n",
       "        [40., 40., 40.]], dtype=float32)>,\n",
       " <tf.Tensor: id=12652, shape=(4, 3), dtype=float32, numpy=\n",
       " array([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [3., 2., 1.],\n",
       "        [4., 4., 4.]], dtype=float32)>,\n",
       " <tf.Tensor: id=12656, shape=(4, 1), dtype=float32, numpy=\n",
       " array([[1.],\n",
       "        [4.],\n",
       "        [3.],\n",
       "        [4.]], dtype=float32)>,\n",
       " <tf.Tensor: id=12660, shape=(4, 2), dtype=float32, numpy=\n",
       " array([[2., 3.],\n",
       "        [5., 6.],\n",
       "        [2., 1.],\n",
       "        [4., 4.]], dtype=float32)>)"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ap, A, θϕ, xs, xt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss with an extra input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.enable_eager_execution()\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred, attention):\n",
    "#     y_true, y_pred, attention = inputs[0], inputs[1], inputs[1]\n",
    "    y_pred_att = tf.multiply(y_pred, attention)\n",
    "    loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred_att)\n",
    "    return loss\n",
    "\n",
    "def dummy_loss(y_true, y_pred):\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_wrapper_fn(A):\n",
    "    def loss_fn(y_true, y_pred):\n",
    "        y_pred_att = tf.multiply(y_pred,A)\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred_att)\n",
    "        return loss\n",
    "    return loss_fn #tf.keras.losses.sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/da/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "input_shape = (28, 28)\n",
    "\n",
    "inp = keras.layers.Input(shape=input_shape)\n",
    "flat = keras.layers.Flatten(input_shape=(28, 28))(inp)\n",
    "dense = keras.layers.Dense(128, activation='relu')(flat)\n",
    "preds = keras.layers.Dense(10, activation='softmax')(dense)\n",
    "\n",
    "att_layer = keras.layers.Dense(10, activation='softmax')\n",
    "att = att_layer(flat)\n",
    "\n",
    "labels = tf.keras.layers.Input(shape=(1,)) \n",
    "\n",
    "model=keras.models.Model(inputs=[inp, labels], outputs=[preds, att])\n",
    "\n",
    "\n",
    "# preds_att = tf.multiply(preds, att)\n",
    "# loss = tf.keras.losses.sparse_categorical_crossentropy(labels, preds_att)\n",
    "\n",
    "loss = custom_loss(labels, preds, att)\n",
    "model.add_loss(loss)\n",
    "acc = tf.keras.metrics.sparse_categorical_accuracy(labels, preds)\n",
    "model.add_metric(acc, name='acc', aggregation='mean')\n",
    "\n",
    "# loss_layer = tf.keras.layers.Lambda(custom_loss)([labels, preds, att])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output dense_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to dense_1.\n",
      "WARNING:tensorflow:Output dense_2 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to dense_2.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "#               metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/da/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 60000 samples\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.4960 - acc: 0.7887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x10f43bcc0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[train_images, train_labels], epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_layer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_layer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter():\n",
    "    c = 0\n",
    "    while True:\n",
    "        c += 1\n",
    "        yield c\n",
    "count = counter()\n",
    "\n",
    "def zeros(shape, dtype=tf.bool):\n",
    "    name = 'zeros_{}'.format(next(count))\n",
    "    return tf.zeros(shape, dtype, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.constant([[0,0,1,0],\n",
    "                 [0,0,0,1],\n",
    "                 [1,0,0,0],\n",
    "                 [0,1,0,0]], dtype=tf.float32)\n",
    "I = tf.ones([4,4], dtype=tf.float32)\n",
    "A = tf.constant([[1,1,0,0],\n",
    "                 [1,1,0,0],\n",
    "                 [0,0,1,1],\n",
    "                 [0,0,1,1]], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=44, shape=(), dtype=float32, numpy=2.828427>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.norm(tf.multiply(I-W, A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=20093, shape=(4, 2), dtype=bool, numpy=\n",
       " array([[ True, False],\n",
       "        [False,  True],\n",
       "        [False,  True],\n",
       "        [ True, False]])>,\n",
       " <tf.Tensor: id=20094, shape=(4, 3), dtype=float32, numpy=\n",
       " array([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [3., 2., 1.],\n",
       "        [4., 4., 4.]], dtype=float32)>)"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = tf.constant([[True, False], [False, True],\n",
    "                 [False, True], [True, False]])\n",
    "\n",
    "x = tf.constant([[1,2,3],[4,5,6],\n",
    "                 [3,2,1],[4,4,4]], dtype=tf.float32)\n",
    "C = 2\n",
    "N = 4\n",
    "D = 3\n",
    "y, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=1733, shape=(4, 4, 2), dtype=bool, numpy=\n",
       " array([[[ True, False],\n",
       "         [ True, False],\n",
       "         [ True, False],\n",
       "         [ True, False]],\n",
       " \n",
       "        [[False,  True],\n",
       "         [False,  True],\n",
       "         [False,  True],\n",
       "         [False,  True]],\n",
       " \n",
       "        [[False,  True],\n",
       "         [False,  True],\n",
       "         [False,  True],\n",
       "         [False,  True]],\n",
       " \n",
       "        [[False,  True],\n",
       "         [False,  True],\n",
       "         [False,  True],\n",
       "         [False,  True]]])>,\n",
       " <tf.Tensor: id=1737, shape=(4, 4, 2), dtype=bool, numpy=\n",
       " array([[[ True, False],\n",
       "         [False,  True],\n",
       "         [False,  True],\n",
       "         [False,  True]],\n",
       " \n",
       "        [[ True, False],\n",
       "         [False,  True],\n",
       "         [False,  True],\n",
       "         [False,  True]],\n",
       " \n",
       "        [[ True, False],\n",
       "         [False,  True],\n",
       "         [False,  True],\n",
       "         [False,  True]],\n",
       " \n",
       "        [[ True, False],\n",
       "         [False,  True],\n",
       "         [False,  True],\n",
       "         [False,  True]]])>)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTe = tf.broadcast_to(tf.expand_dims(y, axis=1), shape=(N, N, C))\n",
    "eTy = tf.broadcast_to(tf.expand_dims(y, axis=0), shape=(N, N, C))\n",
    "yTe, eTy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=239, shape=(4, 4, 2), dtype=bool, numpy=\n",
       "array([[[ True, False],\n",
       "        [False, False],\n",
       "        [False, False],\n",
       "        [False, False]],\n",
       "\n",
       "       [[False, False],\n",
       "        [False,  True],\n",
       "        [False,  True],\n",
       "        [False,  True]],\n",
       "\n",
       "       [[False, False],\n",
       "        [False,  True],\n",
       "        [False,  True],\n",
       "        [False,  True]],\n",
       "\n",
       "       [[False, False],\n",
       "        [False,  True],\n",
       "        [False,  True],\n",
       "        [False,  True]]])>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = tf.cast(tf.logical_and(yTe, eTy),dtype=tf.bool)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=255, shape=(4, 4, 2), dtype=bool, numpy=\n",
       "array([[[False, False],\n",
       "        [False, False],\n",
       "        [ True,  True],\n",
       "        [ True,  True]],\n",
       "\n",
       "       [[False, False],\n",
       "        [False, False],\n",
       "        [ True,  True],\n",
       "        [ True,  True]],\n",
       "\n",
       "       [[ True,  True],\n",
       "        [ True,  True],\n",
       "        [False, False],\n",
       "        [False, False]],\n",
       "\n",
       "       [[ True,  True],\n",
       "        [ True,  True],\n",
       "        [False, False],\n",
       "        [False, False]]])>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_size = [N//2,N//2,C]\n",
    "O = tf.zeros(tile_size, dtype=tf.bool)\n",
    "I = tf.ones(tile_size, dtype=tf.bool)\n",
    "mask = tf.concat([tf.concat([O, I], axis=0),\n",
    "                  tf.concat([I, O], axis=0)], axis=1 )\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_mask = tf.logical_and(W,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.cast(W, dtype=tf.float32)\n",
    "W_mask = tf.cast(W_mask, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=301, shape=(4, 4), dtype=float32, numpy=\n",
       " array([[1., 0., 0., 0.],\n",
       "        [0., 1., 1., 1.],\n",
       "        [0., 1., 1., 1.],\n",
       "        [0., 1., 1., 1.]], dtype=float32)>,\n",
       " <tf.Tensor: id=303, shape=(4, 4), dtype=float32, numpy=\n",
       " array([[0., 0., 0., 0.],\n",
       "        [0., 0., 1., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.]], dtype=float32)>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(W, axis=2), tf.reduce_sum(W_mask, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = tf.constant(np.arange(0, D*D*C, dtype=np.float32), shape=[C,D,D])\n",
    "bias = tf.constant(np.arange(0, C*D, dtype=np.float32), shape=[C,D])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2682, shape=(2, 4, 3), dtype=float32, numpy=\n",
       "array([[[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [3., 2., 1.],\n",
       "        [4., 4., 4.]],\n",
       "\n",
       "       [[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [3., 2., 1.],\n",
       "        [4., 4., 4.]]], dtype=float32)>"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTe = tf.broadcast_to(tf.expand_dims(x, axis=0), shape=(C, N, D))\n",
    "xTe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(2), Dimension(4), Dimension(3)]),\n",
       " TensorShape([Dimension(4), Dimension(4), Dimension(2)]))"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTe.shape, W_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=2744, shape=(2, 4, 3), dtype=float32, numpy=\n",
       " array([[[ 24.,  31.,  38.],\n",
       "         [ 51.,  67.,  83.],\n",
       "         [ 12.,  19.,  26.],\n",
       "         [ 36.,  49.,  62.]],\n",
       " \n",
       "        [[ 81.,  88.,  95.],\n",
       "         [189., 205., 221.],\n",
       "         [ 69.,  76.,  83.],\n",
       "         [147., 160., 173.]]], dtype=float32)>,\n",
       " <tf.Tensor: id=2745, shape=(2, 4, 4), dtype=float32, numpy=\n",
       " array([[[  2981.,   6455.,   1865.,   4739.],\n",
       "         [  6455.,  13979.,   4043.,  10265.],\n",
       "         [  1865.,   4043.,   1181.,   2975.],\n",
       "         [  4739.,  10265.,   2975.,   7541.]],\n",
       " \n",
       "        [[ 23330.,  54344.,  20162.,  42422.],\n",
       "         [ 54344., 126587.,  46964.,  98816.],\n",
       "         [ 20162.,  46964.,  17426.,  36662.],\n",
       "         [ 42422.,  98816.,  36662.,  77138.]]], dtype=float32)>)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.broadcast_to(tf.expand_dims(bias, axis=1), shape=(C, N, D))\n",
    "xB = tf.matmul(xTe, B) + b\n",
    "xBBx = tf.matmul(xB, xB, transpose_b=True)\n",
    "# xBx = tf.matmul(tf.matmul(xTe, B), xTe, transpose_b=True)\n",
    "# xBx = tf.transpose(xBx, perm=[1,2,0])\n",
    "# xBx\n",
    "xB, xBBx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast_x(x, C):\n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "\n",
    "    xTe = tf.broadcast_to(tf.expand_dims(x, axis=0), shape=(C, N, D))\n",
    "    return xTe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3978, shape=(4, 4), dtype=float32, numpy=\n",
       "array([[   0.,    0.,    0.,    0.],\n",
       "       [   0.,    0., 1176., 2412.],\n",
       "       [   0., 1092.,    0.,    0.],\n",
       "       [   0., 2364.,    0.,    0.]], dtype=float32)>"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_attention(x, y, B):\n",
    "    N = y.shape[0]\n",
    "    C = y.shape[1]\n",
    "    D = x.shape[1]\n",
    "    \n",
    "    # create W\n",
    "    yTe = tf.broadcast_to(tf.expand_dims(y, axis=1), shape=(N, N, C))\n",
    "    eTy = tf.broadcast_to(tf.expand_dims(y, axis=0), shape=(N, N, C))\n",
    "    W_full = tf.logical_and(yTe, eTy)\n",
    "\n",
    "    # create W_st (source-target)\n",
    "    tile_size = [N//2,N//2,C]\n",
    "    O = tf.zeros(tile_size, dtype=tf.bool)\n",
    "    I = tf.ones(tile_size, dtype=tf.bool)\n",
    "    mask = tf.concat([tf.concat([O, I], axis=0),\n",
    "                      tf.concat([I, O], axis=0)], axis=1 )\n",
    "    W_st = tf.logical_and(W_full, mask)\n",
    "\n",
    "    # create xBBx\n",
    "    bias = tf.constant(np.arange(0, (C*D).value, dtype=np.float32), shape=[C,D])\n",
    "    b = tf.broadcast_to(tf.expand_dims(bias, axis=1), shape=(C, N, D))\n",
    "    xB = tf.matmul(xTe, B) + b\n",
    "    xBBx = tf.matmul(xB, xB, transpose_b=True)\n",
    "    xBBx = tf.transpose(xBBx, perm=[1,2,0])\n",
    "\n",
    "    # mask using W\n",
    "    A_C = tf.where(W_st, xBx, tf.zeros_like(xBx))\n",
    "    A = tf.reduce_sum(A_C, axis=2)\n",
    "    return A\n",
    "\n",
    "D, C = 3, 2\n",
    "B = tf.constant(np.arange(0, (D*D*C), dtype=np.float32), shape=[C,D,D])\n",
    "\n",
    "get_attention(x,y,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2587, shape=(4, 4), dtype=float32, numpy=\n",
       "array([[    0.,     0.,     0.,     0.],\n",
       "       [    0.,     0., 43596., 94428.],\n",
       "       [    0., 43596.,     0.,     0.],\n",
       "       [    0., 94428.,     0.,     0.]], dtype=float32)>"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_layer = tf.keras.layers.Lambda(lambda z: get_attention(z[0],z[1], z[2]))\n",
    "attention_layer([x, y, B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=2639, shape=(2, 4, 3), dtype=float32, numpy=\n",
       " array([[[1., 2., 3.],\n",
       "         [4., 5., 6.],\n",
       "         [3., 2., 1.],\n",
       "         [4., 4., 4.]],\n",
       " \n",
       "        [[1., 2., 3.],\n",
       "         [4., 5., 6.],\n",
       "         [3., 2., 1.],\n",
       "         [4., 4., 4.]]], dtype=float32)>,\n",
       " <tf.Tensor: id=2675, shape=(2, 4, 3), dtype=float32, numpy=\n",
       " array([[[-1.9459436 , -1.4866495 ,  0.64783645],\n",
       "         [-4.4430037 , -4.626745  ,  0.27498078],\n",
       "         [-1.3834698 , -2.7001448 , -1.1449773 ],\n",
       "         [-3.3294134 , -4.1867943 , -0.49714088]],\n",
       " \n",
       "        [[-1.9459436 , -1.4866495 ,  0.64783645],\n",
       "         [-4.4430037 , -4.626745  ,  0.27498078],\n",
       "         [-1.3834698 , -2.7001448 , -1.1449773 ],\n",
       "         [-3.3294134 , -4.1867943 , -0.49714088]]], dtype=float32)>)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C, D = 2,3\n",
    "def broadcast_x(x, C):\n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "    xTe = tf.broadcast_to(tf.expand_dims(x, axis=0), shape=(C, N, D))\n",
    "    return xTe\n",
    "\n",
    "broadcast_layer = keras.layers.Lambda(lambda x: broadcast_x(x, C))\n",
    "B_layer = keras.layers.Dense(D, activation=None, kernel_initializer='glorot_uniform', bias_initializer='zeros', name='att_B')\n",
    "\n",
    "xTe = broadcast_layer(x)\n",
    "xTe, B_layer(xTe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'att_B/kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
       " array([[ 0.40792704,  0.01533341,  0.9023566 ],\n",
       "        [ 0.16194725,  0.4354167 ,  0.43807793],\n",
       "        [-0.9853258 ,  0.10133934,  0.68444157]], dtype=float32)>,\n",
       " <tf.Variable 'att_B/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_layer.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import activations\n",
    "from tensorflow.python.keras import constraints\n",
    "from tensorflow.python.keras import initializers\n",
    "from tensorflow.python.keras import regularizers\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.keras.engine.input_spec import InputSpec\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class DenseAttention(Layer):\n",
    "\n",
    "    def __init__(self,\n",
    "                 classes,\n",
    "                 omit_intra_domain=True,\n",
    "                 activation='softmax',\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
    "\n",
    "        super(DenseAttention, self).__init__(activity_regularizer=regularizers.get(activity_regularizer), **kwargs)\n",
    "        self.classes = int(classes)\n",
    "        self.omit_intra_domain = omit_intra_domain\n",
    "        self.activation = activations.get(activation)\n",
    "        self.use_bias = use_bias\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.input_spec = InputSpec(min_ndim=2)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        dtype = dtypes.as_dtype(self.dtype or K.floatx())\n",
    "        if not (dtype.is_floating or dtype.is_complex):\n",
    "            raise TypeError('Unable to build `Dense` layer with non-floating point dtype %s' % (dtype,))\n",
    "        input_shape = tensor_shape.TensorShape(input_shape) # N x D\n",
    "        self.dims = tensor_shape.dimension_value(input_shape[-1])\n",
    "        if self.dims is None:\n",
    "            raise ValueError('The last dimension of the inputs to `DenseAttention` should be defined. Found `None`.')\n",
    "        \n",
    "        self.input_spec = InputSpec(min_ndim=2, axes={ -1: self.dims})\n",
    "        weight_shape = [self.classes, self.dims, self.dims] # C x D x D\n",
    "        bias_shape = [self.classes, self.dims] # C x D\n",
    "        \n",
    "        self.kernel = self.add_weight(\n",
    "            'kernel',\n",
    "            shape=weight_shape,\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint,\n",
    "            dtype=self.dtype,\n",
    "            trainable=True\n",
    "        )\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(\n",
    "                'bias',\n",
    "                shape=bias_shape,\n",
    "                initializer=self.bias_initializer,\n",
    "                regularizer=self.bias_regularizer,\n",
    "                constraint=self.bias_constraint,\n",
    "                dtype=self.dtype,\n",
    "                trainable=True\n",
    "            )\n",
    "        else:\n",
    "            self.bias = None\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, labels):\n",
    "        rank = len(inputs.shape)\n",
    "        if rank != 2:\n",
    "            raise ValueError('The input to `DenseAttention` should be of rank 2, but got input of shape %s'% input_shape)\n",
    "        if K.is_sparse(inputs):\n",
    "            raise ValueError(\"`DenseAttention` doesn't support SparseTensor as input\")\n",
    "            outputs = sparse_ops.sparse_tensor_dense_matmul(inputs, self.kernel)\n",
    "            \n",
    "        inputs = math_ops.cast(inputs, self._compute_dtype)\n",
    "        num_samples = tensor_shape.dimension_value(inputs.shape[0])\n",
    "        \n",
    "        # broadcast input to the number of classes\n",
    "        inputs_shape_b = [self.classes, num_samples, self.dims]\n",
    "        xTe = tf.broadcast_to(tf.expand_dims(inputs, axis=0), shape=inputs_shape_b)\n",
    "        \n",
    "        # apply attention-weights\n",
    "        xB = tf.matmul(xTe, self.kernel)\n",
    "        if self.use_bias:\n",
    "            bias = tf.broadcast_to(tf.expand_dims(self.bias, axis=1), shape=inputs_shape_b)\n",
    "            xB = tf.add(xB, bias)\n",
    "        xBBx = tf.matmul(xB, xB, transpose_b=True)\n",
    "        xBBx = tf.transpose(xBBx, perm=[1,2,0])\n",
    "        \n",
    "        # create masking according to samples classes\n",
    "        labels_shape_b = [num_samples, num_samples, self.classes ]\n",
    "        yTe = tf.broadcast_to(tf.expand_dims(labels, axis=1), shape=labels_shape_b)\n",
    "        eTy = tf.broadcast_to(tf.expand_dims(labels, axis=0), shape=labels_shape_b)\n",
    "        W = tf.equal(yTe, eTy)\n",
    "\n",
    "        if self.omit_intra_domain:\n",
    "            tile_size = [num_samples//2, num_samples//2, self.classes]\n",
    "            zeros = tf.zeros(tile_size, dtype=tf.bool)\n",
    "            ones = tf.ones(tile_size, dtype=tf.bool)\n",
    "            mask = tf.concat([tf.concat([zeros, ones], axis=0),\n",
    "                              tf.concat([ones, zeros], axis=0)], axis=1 )\n",
    "            W = tf.logical_and(W, mask)\n",
    "\n",
    "        A = tf.where(W, xBBx, tf.zeros_like(xBBx)) # mask using W\n",
    "        \n",
    "        if self.activation is not None:\n",
    "            A = tf.reshape(A,[C, num_samples*num_samples])\n",
    "            A = self.activation(A) # pylint: disable=not-callable\n",
    "            A = tf.reshape(A,[num_samples,num_samples, C])\n",
    "            A = tf.where(W, A, tf.zeros_like(A)) # mask again to remove spill-over from softmax\n",
    "            \n",
    "        outputs = tf.reduce_sum(A, axis=2) #reduce along the channel axis\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        input_shape = tensor_shape.TensorShape(input_shape)\n",
    "        input_shape = input_shape.with_rank_at_least(2)\n",
    "        if tensor_shape.dimension_value(input_shape[-1]) is None:\n",
    "            raise ValueError('The innermost dimension of input_shape must be defined, but saw: %s'% input_shape)\n",
    "        return [input_shape[0], input_shape[0]]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'classes': self.classes,\n",
    "            'activation': activations.serialize(self.activation),\n",
    "            'use_bias': self.use_bias,\n",
    "            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n",
    "            'bias_initializer': initializers.serialize(self.bias_initializer),\n",
    "            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n",
    "            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
    "            'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n",
    "            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n",
    "            'bias_constraint': constraints.serialize(self.bias_constraint)\n",
    "        }\n",
    "        base_config = super(DenseAttention, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=20094, shape=(4, 3), dtype=float32, numpy=\n",
       " array([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [3., 2., 1.],\n",
       "        [4., 4., 4.]], dtype=float32)>,\n",
       " <tf.Tensor: id=20093, shape=(4, 2), dtype=bool, numpy=\n",
       " array([[ True, False],\n",
       "        [False,  True],\n",
       "        [False,  True],\n",
       "        [ True, False]])>)"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=21308, shape=(4, 4), dtype=float32, numpy=\n",
       " array([[ 0.      ,  0.      ,  0.      , 32.96839 ],\n",
       "        [ 0.      ,  0.      , 34.157997,  0.      ],\n",
       "        [ 0.      , 34.157997,  0.      ,  0.      ],\n",
       "        [32.96839 ,  0.      ,  0.      ,  0.      ]], dtype=float32)>,\n",
       " <tf.Tensor: id=21382, shape=(4, 4), dtype=float32, numpy=\n",
       " array([[0.       , 0.       , 0.       , 1.9827853],\n",
       "        [0.       , 0.       , 1.9999979, 0.       ],\n",
       "        [0.       , 1.9999979, 0.       , 0.       ],\n",
       "        [1.9827853, 0.       , 0.       , 0.       ]], dtype=float32)>,\n",
       " <tf.Tensor: id=21456, shape=(4, 4), dtype=float32, numpy=\n",
       " array([[0.        , 0.        , 0.        , 0.87377375],\n",
       "        [0.        , 0.        , 0.12622614, 0.        ],\n",
       "        [0.        , 0.12622614, 0.        , 0.        ],\n",
       "        [0.87377375, 0.        , 0.        , 0.        ]], dtype=float32)>)"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_layer = DenseAttention(classes=y.shape[1], use_bias=True, activation=None)\n",
    "attention_layer_th = DenseAttention(classes=y.shape[1], use_bias=True, activation='tanh')\n",
    "attention_layer_sm = DenseAttention(classes=y.shape[1], use_bias=True, activation='softmax')\n",
    "attention_layer(x,y), attention_layer_th(x,y), attention_layer_sm(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.        0.        0.        0.      ]\n",
      " [ 0.        0.       24.994654 57.475113]\n",
      " [ 0.       24.994654  0.        0.      ]\n",
      " [ 0.       57.475113  0.        0.      ]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1.0936431e-25 1.0936431e-25 1.0936431e-25 1.0936431e-25]\n",
      " [1.0936431e-25 1.0936431e-25 7.8327627e-15 1.0000000e+00]\n",
      " [1.0936431e-25 7.8327627e-15 1.0936431e-25 1.0936431e-25]\n",
      " [1.0936431e-25 1.0000000e+00 1.0936431e-25 1.0936431e-25]], shape=(4, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "o = attention_layer(x,y)\n",
    "print(o)\n",
    "o = tf.reshape(o,[1,N*N])\n",
    "o = 2*activations.get('softmax')(o)\n",
    "o = tf.reshape(o,[N,N])\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=9107, shape=(4,), dtype=float32, numpy=\n",
       "array([4.3745724e-25, 1.0000000e+00, 7.8327627e-15, 1.0000000e+00],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(o, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
